{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52500, 784)\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed: 41.5min\n",
      "[Parallel(n_jobs=2)]: Done  90 out of  90 | elapsed: 81.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.965\n",
      "Best parameters set:\n",
      "\tclf__C: 3\n",
      "\tclf__gamma: 0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98      1760\n",
      "         1.0       0.98      0.98      0.98      1989\n",
      "         2.0       0.95      0.97      0.96      1721\n",
      "         3.0       0.96      0.96      0.96      1807\n",
      "         4.0       0.96      0.97      0.97      1713\n",
      "         5.0       0.96      0.96      0.96      1535\n",
      "         6.0       0.98      0.98      0.98      1718\n",
      "         7.0       0.98      0.96      0.97      1773\n",
      "         8.0       0.96      0.96      0.96      1721\n",
      "         9.0       0.96      0.95      0.96      1763\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     17500\n",
      "   macro avg       0.97      0.97      0.97     17500\n",
      "weighted avg       0.97      0.97      0.97     17500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = fetch_mldata('MNIST original', data_home='data/mnist')\n",
    "    X, y = data.data, data.target\n",
    "    X = X/255.0*2 - 1\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('clf', SVC(kernel='rbf', gamma=0.01, C=100))\n",
    "    ])\n",
    "    print(X_train.shape)\n",
    "    parameters = {\n",
    "        'clf__gamma': (0.01, 0.03, 0.1, 0.3, 1),\n",
    "        'clf__C': (0.1, 0.3, 1, 3, 10, 30),\n",
    "    }\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=2,\n",
    "                              verbose=1, scoring='accuracy')\n",
    "    grid_search.fit(X_train[:10000], y_train[:10000])\n",
    "    print('Best score: %0.3f' % grid_search.best_score_)\n",
    "    print('Best parameters set:')\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "    predictions = grid_search.predict(X_test)\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
